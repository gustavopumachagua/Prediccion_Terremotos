{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción de magnitud**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Puedes utilizar una regresión para predecir la magnitud de los terremotos (variable \"Mag\") basándote en otras características como la profundidad, la ubicación geográfica (latitud y longitud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE): 0.20646767075673436\n",
      "Coeficiente de determinación (R2): 0.0023945363077092496\n",
      "Latitud introducida es: 50.0\n",
      "Longitud introducida es: 50.0\n",
      "Profundidad introducida es: 500.0\n",
      "Según los valores ingresados, la predicción de la magnitud es: 5.98\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Seleccionar características relevantes\n",
    "features = ['Latitude', 'Longitude', 'Depth']\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data[features]\n",
    "y = data['Mag']\n",
    "\n",
    "# Crear un modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo utilizando los datos completos\n",
    "model.fit(X, y)\n",
    "\n",
    "# Realizar predicciones utilizando los datos completos\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print('Error cuadrático medio (MSE):', mse)\n",
    "\n",
    "# Calcular el coeficiente de determinación (R2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('Coeficiente de determinación (R2):', r2)\n",
    "\n",
    "# Función para validar la entrada de datos\n",
    "def validar_valor(mensaje, valor_min, valor_max):\n",
    "    while True:\n",
    "        try:\n",
    "            valor = float(input(mensaje))\n",
    "            if valor_min <= valor <= valor_max:\n",
    "                return valor\n",
    "            else:\n",
    "                print(f'Por favor, ingrese un valor entre {valor_min} y {valor_max}.')\n",
    "        except ValueError:\n",
    "            print('Por favor, ingrese un valor numérico válido.')\n",
    "\n",
    "# Solicitar datos de entrada al usuario con validación\n",
    "latitude, longitude, depth = None, None, None\n",
    "\n",
    "while latitude is None:\n",
    "    latitude = validar_valor('Ingrese la latitud (-90 a 90 grados): ', -90, 90)\n",
    "\n",
    "while longitude is None:\n",
    "    longitude = validar_valor('Ingrese la longitud (-180 a 180 grados): ', -180, 180)\n",
    "\n",
    "while depth is None:\n",
    "    depth = validar_valor('Ingrese la profundidad (0 a 6371 kilómetros): ', 0, 6371)\n",
    "\n",
    "# Imprimir los valores ingresados por el usuario\n",
    "print(f'Latitud introducida es: {latitude}')\n",
    "print(f'Longitud introducida es: {longitude}')\n",
    "print(f'Profundidad introducida es: {depth}')\n",
    "\n",
    "# Crear un DataFrame con los datos de entrada\n",
    "input_data = pd.DataFrame([[latitude, longitude, depth]], columns=features)\n",
    "\n",
    "# Realizar la predicción\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(f'Según los valores ingresados, la predicción de la magnitud es: {prediction[0]:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explicación detallada:**\n",
    "\n",
    "1. Se importa la biblioteca `pandas` para cargar y manipular los datos, y se importa la clase `LinearRegression` de `sklearn.linear_model` para crear un modelo de regresión lineal.\n",
    "2. Se carga el archivo `CSV` usando `pd.read_csv` y se asigna a la variable `data`.\n",
    "3. Se define la lista `features` que contiene las características relevantes para la predicción (`Latitude`, `Longitude`, `Depth`).\n",
    "4. Se separan las características (`X`) y las etiquetas (`y`) del DataFrame `data`.\n",
    "5. Se crea una instancia del modelo de regresión lineal utilizando `LinearRegression()`.\n",
    "6. Se entrena el modelo utilizando los datos completos con `model.fit(X, y)`.\n",
    "7. Se realizan las predicciones utilizando `model.predict(X)` y se asignan a `y_pred`.\n",
    "8. Se calcula el error cuadrático medio (`MSE`) utilizando `mean_squared_error(y, y_pred)` y se muestra en pantalla.\n",
    "9. Se calcula el coeficiente de determinación (`R2`) utilizando `r2_score(y, y_pred)` y se muestra en pantalla.\n",
    "10. Se solicitan los datos de entrada al usuario (`latitud`, `longitud` y `profundidad`) utilizando `input()` y se convierten a números de punto flotante.\n",
    "11. Se crea un nuevo DataFrame `input_data` con los datos de entrada.\n",
    "12. Se realiza la predicción utilizando `model.predict(input_data)` y se asigna a `prediction`.\n",
    "13. Se muestra la predicción en pantalla.\n",
    "\n",
    "Este código optimizado carga los datos una sola vez, entrena el modelo y realiza las predicciones con mayor eficiencia. Además, se calcula y muestra tanto el error cuadrático medio (`MSE`) como el coeficiente de determinación (`R2`) para evaluar el rendimiento del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción del tipo de terremoto**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Puedes desarrollar un modelo de clasificación para predecir el tipo de terremoto (variable \"Type\") en función de las características como la magnitud, la profundidad, la ubicación geográfica, entre otros. Esto podría ayudar a identificar si un terremoto es de tipo \"tectónico\", \"volcánico\" u otro tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.994964886709951\n",
      "Latitud introducida es: 50.0\n",
      "Longitud introducida es: 50.0\n",
      "Profundidad introducida es: 500.0\n",
      "Magnitud introducida es: 5.5\n",
      "La predicción del tipo de terremoto es: earthquake\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Seleccionar las características relevantes para la predicción\n",
    "features = ['Latitude', 'Longitude', 'Depth', 'Mag']\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data[features]\n",
    "y = data['Type']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos de entrenamiento y prueba\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear un modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento escalados\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precisión del modelo:', accuracy)\n",
    "\n",
    "# Función para validar valores dentro de un rango\n",
    "def validar_rango(mensaje, valor_min, valor_max):\n",
    "    while True:\n",
    "        try:\n",
    "            valor = float(input(mensaje))\n",
    "            if valor_min <= valor <= valor_max:\n",
    "                return valor\n",
    "            else:\n",
    "                print(f'Por favor, ingrese un valor entre {valor_min} y {valor_max}.')\n",
    "        except ValueError:\n",
    "            print(f'Por favor, ingrese un valor numérico válido entre {valor_min} y {valor_max}.')\n",
    "\n",
    "# Solicitar datos interactivamente para realizar la predicción con validaciones\n",
    "input_latitude = validar_rango('Ingrese la latitud (-90 a 90 grados): ', -90, 90)\n",
    "input_longitude = validar_rango('Ingrese la longitud (-180 a 180 grados): ', -180, 180)\n",
    "input_depth = validar_rango('Ingrese la profundidad (0 a 6371 kilómetros): ', 0, 6371)\n",
    "input_mag = validar_rango('Ingrese la magnitud (1 a 10): ', 1, 10)\n",
    "\n",
    "# Mostrar los valores ingresados correctamente\n",
    "print(f'Latitud introducida es: {input_latitude}')\n",
    "print(f'Longitud introducida es: {input_longitude}')\n",
    "print(f'Profundidad introducida es: {input_depth}')\n",
    "print(f'Magnitud introducida es: {input_mag}')\n",
    "\n",
    "# Crear un diccionario con los datos de entrada\n",
    "input_data = {\n",
    "    'Latitude': [input_latitude],\n",
    "    'Longitude': [input_longitude],\n",
    "    'Depth': [input_depth],\n",
    "    'Mag': [input_mag]\n",
    "}\n",
    "\n",
    "# Escalar los datos de entrada\n",
    "input_data_scaled = scaler.transform(pd.DataFrame(input_data))\n",
    "\n",
    "# Realizar la predicción utilizando el modelo\n",
    "prediction = model.predict(input_data_scaled)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print('La predicción del tipo de terremoto es:', prediction[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explicación detallada:**\n",
    "\n",
    "1. Se importa la biblioteca `pandas` para cargar y manipular los datos, y se importan las clases `train_test_split`, `LogisticRegression`, `StandardScaler` y `accuracy_score` de sus respectivas bibliotecas de `sklearn`.\n",
    "2. Se carga el archivo `CSV` utilizando `pd.read_csv` y se asigna a la variable `data`.\n",
    "3. Se seleccionan las características relevantes para la predicción y se asignan a la lista `features`.\n",
    "4. Se dividen los datos en características (`X`) y etiquetas (`y`) utilizando `data[features]` y `data['Type']`, respectivamente.\n",
    "5. Se dividen los datos en conjuntos de entrenamiento y prueba utilizando `train_test_split`.\n",
    "6. Se escalan los datos de entrenamiento y prueba utilizando `StandardScaler` para asegurar que todas las características tengan la misma escala.\n",
    "7. Se crea una instancia del modelo de regresión logística utilizando `LogisticRegression` y se establece un límite máximo de iteraciones.\n",
    "8. Se entrena el modelo utilizando los datos de entrenamiento escalados con `model.fit`.\n",
    "9. Se realizan predicciones en el conjunto de prueba utilizando `model.predict`.\n",
    "10. Se calcula la precisión del modelo comparando las etiquetas reales del conjunto de prueba con las etiquetas predichas utilizando `accuracy_score` y se muestra en pantalla.\n",
    "11. Se solicitan datos interactivamente al usuario para realizar la predicción.\n",
    "12. Se crea un diccionario con los datos de entrada proporcionados por el usuario.\n",
    "13. Se escalan los datos de entrada utilizando el mismo `StandardScaler` utilizado en los datos de entrenamiento y prueba.\n",
    "14. Se realiza la predicción utilizando el modelo entrenado y los datos de entrada escalados.\n",
    "15. Se muestra la predicción en pantalla.\n",
    "\n",
    "Este código optimizado y detallado divide los datos en conjuntos de entrenamiento y prueba, escala los datos correctamente y calcula la precisión del modelo. Además, solicita los datos de entrada de forma interactiva y realiza la predicción correspondiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción de Country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.5725453822711011\n",
      "Latitud introducida es: 50.0\n",
      "Longitud introducida es: 50.0\n",
      "Profundidad introducida es: 500.0\n",
      "Magnitud introducida es: 5.5\n",
      "La predicción del país es: Alaska\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Seleccionar las características relevantes para la predicción\n",
    "features = ['Latitude', 'Longitude', 'Depth', 'Mag']\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data[features]\n",
    "y = data['Country']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos de entrenamiento y prueba\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear un modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento escalados\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precisión del modelo:', accuracy)\n",
    "\n",
    "# Función para validar valores dentro de un rango\n",
    "def validar_rango(mensaje, valor_min, valor_max):\n",
    "    while True:\n",
    "        try:\n",
    "            valor = float(input(mensaje))\n",
    "            if valor_min <= valor <= valor_max:\n",
    "                return valor\n",
    "            else:\n",
    "                print(f'Por favor, ingrese un valor entre {valor_min} y {valor_max}.')\n",
    "        except ValueError:\n",
    "            print('Por favor, ingrese un valor numérico válido.')\n",
    "\n",
    "# Solicitar datos interactivamente para realizar la predicción con validaciones\n",
    "input_latitude = validar_rango('Ingrese la latitud (-90 a 90 grados): ', -90, 90)\n",
    "input_longitude = validar_rango('Ingrese la longitud (-180 a 180 grados): ', -180, 180)\n",
    "input_depth = validar_rango('Ingrese la profundidad (0 a 6371 kilómetros): ', 0, 6371)\n",
    "input_mag = validar_rango('Ingrese la magnitud (1 a 10): ', 1, 10)\n",
    "\n",
    "# Mostrar los valores ingresados correctamente\n",
    "print(f'Latitud introducida es: {input_latitude}')\n",
    "print(f'Longitud introducida es: {input_longitude}')\n",
    "print(f'Profundidad introducida es: {input_depth}')\n",
    "print(f'Magnitud introducida es: {input_mag}')\n",
    "\n",
    "# Crear un DataFrame con los datos de entrada\n",
    "input_data = pd.DataFrame({\n",
    "    'Latitude': [input_latitude],\n",
    "    'Longitude': [input_longitude],\n",
    "    'Depth': [input_depth],\n",
    "    'Mag': [input_mag]\n",
    "})\n",
    "\n",
    "# Escalar los datos de entrada utilizando el mismo escalador\n",
    "input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "# Realizar la predicción utilizando el modelo\n",
    "prediction = model.predict(input_data_scaled)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print('La predicción del país es:', prediction[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción de Subtype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9941698688220485\n",
      "Latitud introducida es: 50.0\n",
      "Longitud introducida es: 50.0\n",
      "Profundidad introducida es: 500.0\n",
      "Magnitud introducida es: 5.5\n",
      "La predicción del Subtype es: Ground movement\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Seleccionar las características relevantes para la predicción\n",
    "features = ['Latitude', 'Longitude', 'Depth', 'Mag']\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data[features]\n",
    "y = data['Subtype']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos de entrenamiento y prueba\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear un modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento escalados\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precisión del modelo:', accuracy)\n",
    "\n",
    "# Función para validar la entrada de datos\n",
    "def validar_valor(mensaje, valor_min, valor_max):\n",
    "    while True:\n",
    "        try:\n",
    "            valor = float(input(mensaje))\n",
    "            if valor_min <= valor <= valor_max:\n",
    "                return valor\n",
    "            else:\n",
    "                print(f'Por favor, ingrese un valor entre {valor_min} y {valor_max}.')\n",
    "        except ValueError:\n",
    "            print('Por favor, ingrese un valor numérico válido.')\n",
    "\n",
    "# Solicitar datos de entrada al usuario con validación\n",
    "latitude = validar_valor('Ingrese la latitud (-90 a 90 grados): ', -90, 90)\n",
    "longitude = validar_valor('Ingrese la longitud (-180 a 180 grados): ', -180, 180)\n",
    "depth = validar_valor('Ingrese la profundidad (0 a 6371 kilómetros): ', 0, 6371)\n",
    "magnitude = validar_valor('Ingrese la magnitud (1 a 10): ', 1, 10)\n",
    "\n",
    "# Mostrar los valores ingresados correctamente\n",
    "print(f'Latitud introducida es: {input_latitude}')\n",
    "print(f'Longitud introducida es: {input_longitude}')\n",
    "print(f'Profundidad introducida es: {input_depth}')\n",
    "print(f'Magnitud introducida es: {input_mag}')\n",
    "\n",
    "# Crear un DataFrame con los datos de entrada\n",
    "input_data = pd.DataFrame({\n",
    "    'Latitude': [latitude],\n",
    "    'Longitude': [longitude],\n",
    "    'Depth': [depth],\n",
    "    'Mag': [magnitude]\n",
    "})\n",
    "\n",
    "# Escalar los datos de entrada utilizando el mismo escalador\n",
    "input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "# Realizar la predicción utilizando el modelo\n",
    "prediction = model.predict(input_data_scaled)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print('La predicción del Subtype es:', prediction[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explicación paso a paso:**\n",
    "\n",
    "1. Se cargan los datos desde el archivo `CSV` utilizando `pd.read_csv()` y se asignan a la variable data.\n",
    "\n",
    "2. Se definen las características relevantes para la predicción en la lista features, que en este caso son '`Latitude`', '`Longitude`', '`Depth`' y '`Mag`'.\n",
    "\n",
    "3. Se divide el conjunto de datos en características (`X`) y etiquetas (`y`) utilizando `data[features]` para `X` y `data['Subtype']` para `y`.\n",
    "\n",
    "4. Se divide el conjunto de datos en conjuntos de entrenamiento y prueba utilizando `train_test_split()`. Aquí se reserva el 20% de los datos para pruebas y se utiliza un estado aleatorio de 42 para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "5. Se escala los datos de entrenamiento y prueba utilizando `StandardScaler()` para asegurar que todas las características tengan la misma escala y evitar sesgos en el modelo.\n",
    "\n",
    "6. Se crea un modelo de regresión logística utilizando `LogisticRegression()` con `max_iter=1000` para permitir un mayor número de iteraciones en el ajuste del modelo.\n",
    "\n",
    "7. Se entrena el modelo utilizando los datos de entrenamiento escalados utilizando el método `fit()`.\n",
    "\n",
    "8. Se realizan predicciones en el conjunto de prueba utilizando el método `predict()`.\n",
    "\n",
    "9. Se calcula la precisión del modelo comparando las etiquetas predichas con las etiquetas reales utilizando `accuracy_score()`.\n",
    "\n",
    "10. Se solicitan los datos interactivamente para realizar la predicción utilizando la función `input()`. Cada dato se convierte a float para asegurar que se pueda procesar correctamente.\n",
    "\n",
    "11. Se crea un DataFrame `input_data` con los datos de entrada.\n",
    "\n",
    "12. Se escala los datos de entrada utilizando el mismo escalador `scaler.transform()` para garantizar que se aplique la misma escala que se utilizó para los datos de entrenamiento.\n",
    "\n",
    "13. Se realiza la predicción utilizando el modelo entrenado y los datos de entrada escalados utilizando `model.predict()`.\n",
    "\n",
    "14. Se muestra la predicción resultante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
